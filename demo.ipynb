{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Q&A Agent with LangGraph\n",
    "\n",
    "This notebook demonstrates a Retrieval-Augmented Generation (RAG) question-answering agent built with LangGraph.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "The agent uses a 4-node workflow:\n",
    "\n",
    "```\n",
    "User Question â†’ [PLAN] â†’ [RETRIEVE] â†’ [ANSWER] â†’ [REFLECT] â†’ Response\n",
    "                   â†“          â†“           â†“          â†“\n",
    "                State      State       State      State\n",
    "```\n",
    "\n",
    "- **PLAN**: Determines if retrieval is needed\n",
    "- **RETRIEVE**: Fetches relevant chunks from ChromaDB vector store\n",
    "- **ANSWER**: Generates response using LLM with retrieved context\n",
    "- **REFLECT**: Evaluates answer quality and confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports configured\n",
      "Project root: /var/www/Q-A-AI-Assistant\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (if needed)\n",
    "# !pip install langgraph langchain chromadb sentence-transformers PyPDF2 python-dotenv openai\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath('.')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(\"âœ… Imports configured\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HF_TOKEN loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "if HF_TOKEN:\n",
    "    print(\"âœ… HF_TOKEN loaded successfully\")\n",
    "else:\n",
    "    print(\"âš ï¸ WARNING: HF_TOKEN not found in environment variables\")\n",
    "    print(\"Please create a .env file with: HF_TOKEN=your_token_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import agent components\n",
    "from agents.langgraph_agent import run_workflow, print_result\n",
    "from agents.vector_store import ChromaVectorStore\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Initialize Vector Store\n",
    "\n",
    "We use ChromaDB for persistent vector storage. This provides:\n",
    "- Persistent embeddings (survives restarts)\n",
    "- Metadata support (source file, page numbers)\n",
    "- Semantic similarity search\n",
    "\n",
    "**Why ChromaDB over FAISS?**\n",
    "- ChromaDB offers persistence out of the box\n",
    "- Better metadata filtering capabilities\n",
    "- Simpler API for production use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "ğŸ”§ Initializing ChromaDB at: ./chroma_db\n",
      "âœ… Loaded existing collection 'rag_documents' with 2 documents\n",
      "\n",
      "ğŸ“Š Vector Store Statistics:\n",
      "  Total indexed documents: 2\n",
      "  Collection name: rag_documents\n",
      "  Storage location: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# Initialize ChromaDB vector store\n",
    "vector_store = ChromaVectorStore(data_folder=\"data\")\n",
    "\n",
    "# Get statistics\n",
    "stats = vector_store.get_stats()\n",
    "\n",
    "print(\"\\nğŸ“Š Vector Store Statistics:\")\n",
    "print(f\"  Total indexed documents: {stats['total_documents']}\")\n",
    "print(f\"  Collection name: {stats['collection_name']}\")\n",
    "print(f\"  Storage location: {stats['persist_directory']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Sample retrieval for: 'What is the task about?'\n",
      "\n",
      "Result 1:\n",
      "  Source: task.pdf\n",
      "  Page: 1\n",
      "  Distance: 1.4376\n",
      "  Text preview: TASK 1 Objective: Create a basic AI agent using LangGraph or similar AI Agent framework that can answer questions from a small knowledge base using RA...\n",
      "\n",
      "Result 2:\n",
      "  Source: task.pdf\n",
      "  Page: 2\n",
      "  Distance: 1.5296\n",
      "  Text preview: ï‚· Use Hugging Face or OpenAI embeddings for vector creation. ï‚· Include minimal logging or print statements to show each step â€™s output (plan â†’ retriev...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval - show what's in the knowledge base\n",
    "if stats['total_documents'] > 0:\n",
    "    test_query = \"What is the task about?\"\n",
    "    docs, metas, distances = vector_store.query(test_query, top_k=2)\n",
    "    \n",
    "    print(f\"\\nğŸ” Sample retrieval for: '{test_query}'\\n\")\n",
    "    for i, (doc, meta, dist) in enumerate(zip(docs, metas, distances), 1):\n",
    "        print(f\"Result {i}:\")\n",
    "        print(f\"  Source: {meta.get('source', 'unknown')}\")\n",
    "        print(f\"  Page: {meta.get('page', '?')}\")\n",
    "        print(f\"  Distance: {dist:.4f}\")\n",
    "        print(f\"  Text preview: {doc[:150]}...\\n\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No documents in vector store. Please add PDFs to the 'data/' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: LangGraph Workflow Overview\n",
    "\n",
    "The workflow is defined in `agents/langgraph_agent.py` with the following structure:\n",
    "\n",
    "### State Management\n",
    "An `AgentState` TypedDict flows through all nodes, containing:\n",
    "- `question`: User input\n",
    "- `needs_retrieval`: Plan decision\n",
    "- `retrieved_context`: Retrieved chunks\n",
    "- `retrieved_metadata`: Source info\n",
    "- `answer`: LLM response\n",
    "- `reflection`: Quality evaluation\n",
    "- `steps_log`: Execution trace\n",
    "\n",
    "### Workflow Nodes\n",
    "1. **Plan Node** (`agents/nodes/plan_node.py`): Analyzes if retrieval is needed\n",
    "2. **Retrieve Node** (`agents/nodes/retrieve_node.py`): Performs semantic search\n",
    "3. **Answer Node** (`agents/nodes/answer_node.py`): Generates LLM response\n",
    "4. **Reflect Node** (`agents/nodes/reflect_node.py`): Evaluates quality\n",
    "\n",
    "### Conditional Logic\n",
    "If the plan node determines no retrieval is needed (e.g., simple greetings), the workflow skips directly to the answer node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Test Question 1 - Knowledge Question (With Retrieval)\n",
    "\n",
    "Testing with a question that requires retrieval from the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST 1: KNOWLEDGE QUESTION (WITH RETRIEVAL)\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "ğŸš€ STARTING RAG WORKFLOW\n",
      "============================================================\n",
      "Question: 'What is LangGraph and how is it used?'\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ§  PLAN NODE\n",
      "============================================================\n",
      "Question: 'What is LangGraph and how is it used?'\n",
      "Needs Retrieval: True\n",
      "Reasoning: Knowledge question - retrieval required\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ” RETRIEVE NODE\n",
      "============================================================\n",
      "Question: 'What is LangGraph and how is it used?'\n",
      "Needs Retrieval: True\n",
      "Retrieved 2 chunks:\n",
      "  1. Source: task.pdf, Page: 1, Distance: 1.5000\n",
      "     Preview: TASK 1 Objective: Create a basic AI agent using LangGraph or similar AI Agent framework that can ans...\n",
      "  2. Source: task.pdf, Page: 2, Distance: 1.8921\n",
      "     Preview: ï‚· Use Hugging Face or OpenAI embeddings for vector creation. ï‚· Include minimal logging or print stat...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ’¬ ANSWER NODE\n",
      "============================================================\n",
      "Question: 'What is LangGraph and how is it used?'\n",
      "Context available: 2454 chars\n",
      "Calling LLM...\n",
      "âŒ Error calling LLM: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "âœ… REFLECT NODE\n",
      "============================================================\n",
      "Question: 'What is LangGraph and how is it used?'\n",
      "Answer length: 203 chars\n",
      "\n",
      "Reflection Results:\n",
      "  Quality: good\n",
      "  Confidence: medium\n",
      "  Has Self-Reflection: False\n",
      "  Answer Words: 32\n",
      "  Issues: None\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ WORKFLOW COMPLETE\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ EXECUTION LOG:\n",
      "  â€¢ PLAN: Analyzed question. Retrieval=required\n",
      "  â€¢ RETRIEVE: Found 2 relevant chunks from vector store\n",
      "  â€¢ ANSWER: Generated 203 character response using LLM\n",
      "  â€¢ REFLECT: Quality=good, Confidence=medium\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Question 1: Knowledge question about LangGraph\n",
    "question1 = \"What is LangGraph and how is it used?\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 1: KNOWLEDGE QUESTION (WITH RETRIEVAL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result1 = run_workflow(question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n",
      "ğŸ“Š FINAL RESULT\n",
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n",
      "â“ QUESTION:\n",
      "   What is LangGraph and how is it used?\n",
      "\n",
      "ğŸ§  PLAN:\n",
      "   Retrieval needed: True\n",
      "\n",
      "ğŸ” RETRIEVED SOURCES:\n",
      "   1. task.pdf (Page 1)\n",
      "   2. task.pdf (Page 2)\n",
      "\n",
      "ğŸ’¬ ANSWER:\n",
      "   I apologize, but I encountered an error: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "\n",
      "âœ… REFLECTION:\n",
      "   Quality: good\n",
      "   Confidence: medium\n",
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display detailed results\n",
    "print_result(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ Detailed State Inspection:\n",
      "\n",
      "ğŸ§  PLAN Decision:\n",
      "   Needs Retrieval: True\n",
      "\n",
      "ğŸ” RETRIEVED Context (first 300 chars):\n",
      "   [Source: task.pdf, Page: 1]\n",
      "TASK 1 Objective: Create a basic AI agent using LangGraph or similar AI Agent framework that can answer questions from a small knowledge base using RAG (Retrieval -Augmented Generation) . The goal is to test your understanding of AI agent workflows, RAG pipeline design, a...\n",
      "\n",
      "ğŸ’¬ ANSWER:\n",
      "   I apologize, but I encountered an error: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "\n",
      "âœ… REFLECTION Metrics:\n",
      "   answer_length_chars: 203\n",
      "   answer_length_words: 32\n",
      "   context_used: True\n",
      "   has_reflection: False\n",
      "   confidence: medium\n",
      "   quality: good\n",
      "   issues: []\n"
     ]
    }
   ],
   "source": [
    "# Examine individual state components\n",
    "print(\"\\nğŸ“‹ Detailed State Inspection:\\n\")\n",
    "\n",
    "print(\"ğŸ§  PLAN Decision:\")\n",
    "print(f\"   Needs Retrieval: {result1.get('needs_retrieval')}\")\n",
    "\n",
    "print(\"\\nğŸ” RETRIEVED Context (first 300 chars):\")\n",
    "context = result1.get('retrieved_context', '')\n",
    "print(f\"   {context[:300]}...\" if len(context) > 300 else f\"   {context}\")\n",
    "\n",
    "print(\"\\nğŸ’¬ ANSWER:\")\n",
    "print(f\"   {result1.get('answer', 'N/A')}\")\n",
    "\n",
    "print(\"\\nâœ… REFLECTION Metrics:\")\n",
    "reflection = result1.get('reflection', {})\n",
    "for key, value in reflection.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Test 1\n",
    "\n",
    "The workflow executed all 4 nodes:\n",
    "1. **PLAN** determined retrieval was needed\n",
    "2. **RETRIEVE** fetched relevant chunks from ChromaDB\n",
    "3. **ANSWER** generated a response using the LLM with context\n",
    "4. **REFLECT** evaluated the answer quality\n",
    "\n",
    "This demonstrates the full RAG pipeline in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Test Question 2 - Outside Knowledge Base\n",
    "\n",
    "Testing with a question that is NOT in the knowledge base. The system should:\n",
    "- Still perform retrieval\n",
    "- Find no relevant context\n",
    "- Reflect low confidence in the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST 2: QUESTION OUTSIDE KNOWLEDGE BASE\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "ğŸš€ STARTING RAG WORKFLOW\n",
      "============================================================\n",
      "Question: 'What is quantum computing?'\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ§  PLAN NODE\n",
      "============================================================\n",
      "Question: 'What is quantum computing?'\n",
      "Needs Retrieval: True\n",
      "Reasoning: Knowledge question - retrieval required\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ” RETRIEVE NODE\n",
      "============================================================\n",
      "Question: 'What is quantum computing?'\n",
      "Needs Retrieval: True\n",
      "Retrieved 2 chunks:\n",
      "  1. Source: task.pdf, Page: 2, Distance: 1.8067\n",
      "     Preview: ï‚· Use Hugging Face or OpenAI embeddings for vector creation. ï‚· Include minimal logging or print stat...\n",
      "  2. Source: task.pdf, Page: 1, Distance: 1.8395\n",
      "     Preview: TASK 1 Objective: Create a basic AI agent using LangGraph or similar AI Agent framework that can ans...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ’¬ ANSWER NODE\n",
      "============================================================\n",
      "Question: 'What is quantum computing?'\n",
      "Context available: 2454 chars\n",
      "Calling LLM...\n",
      "âŒ Error calling LLM: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "âœ… REFLECT NODE\n",
      "============================================================\n",
      "Question: 'What is quantum computing?'\n",
      "Answer length: 203 chars\n",
      "\n",
      "Reflection Results:\n",
      "  Quality: good\n",
      "  Confidence: medium\n",
      "  Has Self-Reflection: False\n",
      "  Answer Words: 32\n",
      "  Issues: None\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ WORKFLOW COMPLETE\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ EXECUTION LOG:\n",
      "  â€¢ PLAN: Analyzed question. Retrieval=required\n",
      "  â€¢ RETRIEVE: Found 2 relevant chunks from vector store\n",
      "  â€¢ ANSWER: Generated 203 character response using LLM\n",
      "  â€¢ REFLECT: Quality=good, Confidence=medium\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Question 2: Question outside knowledge base\n",
    "question2 = \"What is quantum computing?\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 2: QUESTION OUTSIDE KNOWLEDGE BASE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result2 = run_workflow(question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n",
      "ğŸ“Š FINAL RESULT\n",
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n",
      "â“ QUESTION:\n",
      "   What is quantum computing?\n",
      "\n",
      "ğŸ§  PLAN:\n",
      "   Retrieval needed: True\n",
      "\n",
      "ğŸ” RETRIEVED SOURCES:\n",
      "   1. task.pdf (Page 2)\n",
      "   2. task.pdf (Page 1)\n",
      "\n",
      "ğŸ’¬ ANSWER:\n",
      "   I apologize, but I encountered an error: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "\n",
      "âœ… REFLECTION:\n",
      "   Quality: good\n",
      "   Confidence: medium\n",
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print_result(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Reflection Analysis:\n",
      "   Confidence level: medium\n"
     ]
    }
   ],
   "source": [
    "# Check if reflection detected low confidence\n",
    "print(\"\\nğŸ” Reflection Analysis:\")\n",
    "reflection2 = result2.get('reflection', {})\n",
    "\n",
    "if reflection2.get('confidence') == 'low':\n",
    "    print(\"   âœ… Reflection correctly identified low confidence\")\n",
    "else:\n",
    "    print(f\"   Confidence level: {reflection2.get('confidence', 'unknown')}\")\n",
    "\n",
    "if reflection2.get('issues'):\n",
    "    print(f\"   Issues detected: {reflection2['issues']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Test 2\n",
    "\n",
    "When the question is outside the knowledge base:\n",
    "- The system still retrieves the most similar chunks\n",
    "- The LLM should indicate insufficient information\n",
    "- The reflection node detects this and marks low confidence\n",
    "\n",
    "This demonstrates the agent's ability to self-evaluate and admit when it doesn't know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Test Question 3 - Simple Query (No Retrieval)\n",
    "\n",
    "Testing the conditional workflow where retrieval is skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST 3: SIMPLE GREETING (NO RETRIEVAL NEEDED)\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "ğŸš€ STARTING RAG WORKFLOW\n",
      "============================================================\n",
      "Question: 'Hello'\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ§  PLAN NODE\n",
      "============================================================\n",
      "Question: 'Hello'\n",
      "Needs Retrieval: False\n",
      "Reasoning: Simple query - no retrieval needed\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ’¬ ANSWER NODE\n",
      "============================================================\n",
      "Question: 'Hello'\n",
      "Context available: 0 chars\n",
      "Calling LLM...\n",
      "âŒ Error calling LLM: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "âœ… REFLECT NODE\n",
      "============================================================\n",
      "Question: 'Hello'\n",
      "Answer length: 203 chars\n",
      "\n",
      "Reflection Results:\n",
      "  Quality: good\n",
      "  Confidence: medium\n",
      "  Has Self-Reflection: False\n",
      "  Answer Words: 32\n",
      "  Issues: None\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ WORKFLOW COMPLETE\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ EXECUTION LOG:\n",
      "  â€¢ PLAN: Analyzed question. Retrieval=not required\n",
      "  â€¢ ANSWER: Generated 203 character response using LLM\n",
      "  â€¢ REFLECT: Quality=good, Confidence=medium\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Question 3: Simple greeting (should skip retrieval)\n",
    "question3 = \"Hello\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 3: SIMPLE GREETING (NO RETRIEVAL NEEDED)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result3 = run_workflow(question3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n",
      "ğŸ“Š FINAL RESULT\n",
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n",
      "â“ QUESTION:\n",
      "   Hello\n",
      "\n",
      "ğŸ§  PLAN:\n",
      "   Retrieval needed: False\n",
      "\n",
      "ğŸ’¬ ANSWER:\n",
      "   I apologize, but I encountered an error: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "\n",
      "âœ… REFLECTION:\n",
      "   Quality: good\n",
      "   Confidence: medium\n",
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print_result(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Workflow Path Verification:\n",
      "   âœ… PLAN correctly determined no retrieval needed\n",
      "   âœ… RETRIEVE was skipped (no context retrieved)\n",
      "\n",
      "ğŸ“‹ Execution Steps:\n",
      "   â€¢ PLAN: Analyzed question. Retrieval=not required\n",
      "   â€¢ ANSWER: Generated 203 character response using LLM\n",
      "   â€¢ REFLECT: Quality=good, Confidence=medium\n"
     ]
    }
   ],
   "source": [
    "# Verify retrieval was skipped\n",
    "print(\"\\nğŸ” Workflow Path Verification:\")\n",
    "\n",
    "if not result3.get('needs_retrieval'):\n",
    "    print(\"   âœ… PLAN correctly determined no retrieval needed\")\n",
    "else:\n",
    "    print(\"   âš ï¸ PLAN decided retrieval was needed\")\n",
    "\n",
    "if not result3.get('retrieved_context'):\n",
    "    print(\"   âœ… RETRIEVE was skipped (no context retrieved)\")\n",
    "else:\n",
    "    print(f\"   Retrieved context length: {len(result3.get('retrieved_context', ''))}\")\n",
    "\n",
    "# Check execution log\n",
    "print(\"\\nğŸ“‹ Execution Steps:\")\n",
    "for step in result3.get('steps_log', []):\n",
    "    print(f\"   â€¢ {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Test 3\n",
    "\n",
    "For simple queries:\n",
    "- The PLAN node uses heuristics to skip retrieval\n",
    "- Workflow goes: PLAN â†’ ANSWER â†’ REFLECT (skipping RETRIEVE)\n",
    "- This saves compute and provides faster responses\n",
    "\n",
    "This demonstrates the conditional branching capability of LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Workflow Execution Log Analysis\n",
    "\n",
    "Let's examine the step-by-step execution for transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXECUTION PATH COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Test 1 (Knowledge Q):\n",
      "  â†’ PLAN: Analyzed question. Retrieval=required\n",
      "  â†’ RETRIEVE: Found 2 relevant chunks from vector store\n",
      "  â†’ ANSWER: Generated 203 character response using LLM\n",
      "  â†’ REFLECT: Quality=good, Confidence=medium\n",
      "\n",
      "Test 2 (Outside KB):\n",
      "  â†’ PLAN: Analyzed question. Retrieval=required\n",
      "  â†’ RETRIEVE: Found 2 relevant chunks from vector store\n",
      "  â†’ ANSWER: Generated 203 character response using LLM\n",
      "  â†’ REFLECT: Quality=good, Confidence=medium\n",
      "\n",
      "Test 3 (Simple Q):\n",
      "  â†’ PLAN: Analyzed question. Retrieval=not required\n",
      "  â†’ ANSWER: Generated 203 character response using LLM\n",
      "  â†’ REFLECT: Quality=good, Confidence=medium\n"
     ]
    }
   ],
   "source": [
    "# Compare execution paths of all three tests\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXECUTION PATH COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tests = [\n",
    "    (\"Test 1 (Knowledge Q)\", result1),\n",
    "    (\"Test 2 (Outside KB)\", result2),\n",
    "    (\"Test 3 (Simple Q)\", result3)\n",
    "]\n",
    "\n",
    "for test_name, result in tests:\n",
    "    print(f\"\\n{test_name}:\")\n",
    "    for step in result.get('steps_log', []):\n",
    "        print(f\"  â†’ {step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PERFORMANCE TEST\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "ğŸš€ STARTING RAG WORKFLOW\n",
      "============================================================\n",
      "Question: 'What is the objective of this task?'\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ§  PLAN NODE\n",
      "============================================================\n",
      "Question: 'What is the objective of this task?'\n",
      "Needs Retrieval: True\n",
      "Reasoning: Knowledge question - retrieval required\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ” RETRIEVE NODE\n",
      "============================================================\n",
      "Question: 'What is the objective of this task?'\n",
      "Needs Retrieval: True\n",
      "Retrieved 2 chunks:\n",
      "  1. Source: task.pdf, Page: 1, Distance: 1.5213\n",
      "     Preview: TASK 1 Objective: Create a basic AI agent using LangGraph or similar AI Agent framework that can ans...\n",
      "  2. Source: task.pdf, Page: 2, Distance: 1.6277\n",
      "     Preview: ï‚· Use Hugging Face or OpenAI embeddings for vector creation. ï‚· Include minimal logging or print stat...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ’¬ ANSWER NODE\n",
      "============================================================\n",
      "Question: 'What is the objective of this task?'\n",
      "Context available: 2454 chars\n",
      "Calling LLM...\n",
      "âŒ Error calling LLM: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "âœ… REFLECT NODE\n",
      "============================================================\n",
      "Question: 'What is the objective of this task?'\n",
      "Answer length: 203 chars\n",
      "\n",
      "Reflection Results:\n",
      "  Quality: good\n",
      "  Confidence: medium\n",
      "  Has Self-Reflection: False\n",
      "  Answer Words: 32\n",
      "  Issues: None\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ WORKFLOW COMPLETE\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ EXECUTION LOG:\n",
      "  â€¢ PLAN: Analyzed question. Retrieval=required\n",
      "  â€¢ RETRIEVE: Found 2 relevant chunks from vector store\n",
      "  â€¢ ANSWER: Generated 203 character response using LLM\n",
      "  â€¢ REFLECT: Quality=good, Confidence=medium\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "â±ï¸ Total execution time: 0.49 seconds\n",
      "ğŸ“Š Steps executed: 4\n"
     ]
    }
   ],
   "source": [
    "# Timing analysis (if available)\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_question = \"What is the objective of this task?\"\n",
    "\n",
    "start_time = time.time()\n",
    "perf_result = run_workflow(test_question)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nâ±ï¸ Total execution time: {execution_time:.2f} seconds\")\n",
    "print(f\"ğŸ“Š Steps executed: {len(perf_result.get('steps_log', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Conclusion and Summary\n",
    "\n",
    "### Agent Capabilities\n",
    "\n",
    "This RAG Q&A agent demonstrates:\n",
    "\n",
    "1. **Modular Architecture**: Clear separation of concerns with 4 distinct nodes\n",
    "2. **State Management**: LangGraph handles state flow between nodes\n",
    "3. **Conditional Logic**: Intelligent routing based on query type\n",
    "4. **Retrieval-Augmented Generation**: Combines vector search with LLM generation\n",
    "5. **Self-Evaluation**: Reflection node assesses answer quality\n",
    "6. **Transparency**: Full execution logging for debugging\n",
    "\n",
    "### Known Limitations\n",
    "\n",
    "1. **Planning Heuristics**: Uses simple keyword matching; could use LLM for better decisions\n",
    "2. **Chunking Strategy**: Fixed 300-word chunks; could benefit from semantic chunking\n",
    "3. **Reflection Depth**: Basic quality metrics; could integrate LLM-as-judge or RAGAs\n",
    "4. **Context Window**: Limited to top-k=3 chunks; might miss relevant information\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "1. **LLM-based Planning**: Use LLM to classify query intent\n",
    "2. **Adaptive Retrieval**: Dynamically adjust top_k based on query complexity\n",
    "3. **Re-ranking**: Add reranker between retrieve and answer nodes\n",
    "4. **Multi-turn Dialogue**: Extend state to support conversation history\n",
    "5. **Evaluation Metrics**: Integrate RAGAs for automated quality assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: Interactive Testing\n",
    "\n",
    "Try your own questions below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing custom question: 'What framework should I use for this task?'\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸš€ STARTING RAG WORKFLOW\n",
      "============================================================\n",
      "Question: 'What framework should I use for this task?'\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ§  PLAN NODE\n",
      "============================================================\n",
      "Question: 'What framework should I use for this task?'\n",
      "Needs Retrieval: True\n",
      "Reasoning: Knowledge question - retrieval required\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ” RETRIEVE NODE\n",
      "============================================================\n",
      "Question: 'What framework should I use for this task?'\n",
      "Needs Retrieval: True\n",
      "Retrieved 2 chunks:\n",
      "  1. Source: task.pdf, Page: 1, Distance: 1.3448\n",
      "     Preview: TASK 1 Objective: Create a basic AI agent using LangGraph or similar AI Agent framework that can ans...\n",
      "  2. Source: task.pdf, Page: 2, Distance: 1.4959\n",
      "     Preview: ï‚· Use Hugging Face or OpenAI embeddings for vector creation. ï‚· Include minimal logging or print stat...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ’¬ ANSWER NODE\n",
      "============================================================\n",
      "Question: 'What framework should I use for this task?'\n",
      "Context available: 2454 chars\n",
      "Calling LLM...\n",
      "âŒ Error calling LLM: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "âœ… REFLECT NODE\n",
      "============================================================\n",
      "Question: 'What framework should I use for this task?'\n",
      "Answer length: 203 chars\n",
      "\n",
      "Reflection Results:\n",
      "  Quality: good\n",
      "  Confidence: medium\n",
      "  Has Self-Reflection: False\n",
      "  Answer Words: 32\n",
      "  Issues: None\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ WORKFLOW COMPLETE\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ EXECUTION LOG:\n",
      "  â€¢ PLAN: Analyzed question. Retrieval=required\n",
      "  â€¢ RETRIEVE: Found 2 relevant chunks from vector store\n",
      "  â€¢ ANSWER: Generated 203 character response using LLM\n",
      "  â€¢ REFLECT: Quality=good, Confidence=medium\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n",
      "ğŸ“Š FINAL RESULT\n",
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n",
      "â“ QUESTION:\n",
      "   What framework should I use for this task?\n",
      "\n",
      "ğŸ§  PLAN:\n",
      "   Retrieval needed: True\n",
      "\n",
      "ğŸ” RETRIEVED SOURCES:\n",
      "   1. task.pdf (Page 1)\n",
      "   2. task.pdf (Page 2)\n",
      "\n",
      "ğŸ’¬ ANSWER:\n",
      "   I apologize, but I encountered an error: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}\n",
      "\n",
      "âœ… REFLECTION:\n",
      "   Quality: good\n",
      "   Confidence: medium\n",
      "\n",
      "ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·ğŸ”·\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interactive testing cell - modify the question and run\n",
    "custom_question = \"What framework should I use for this task?\"\n",
    "\n",
    "print(f\"\\nTesting custom question: '{custom_question}'\\n\")\n",
    "custom_result = run_workflow(custom_question)\n",
    "print_result(custom_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Technical Stack Summary\n",
    "\n",
    "- **Framework**: LangGraph for agent workflow orchestration\n",
    "- **Vector Database**: ChromaDB for persistent embeddings\n",
    "- **Embeddings**: sentence-transformers (all-MiniLM-L6-v2)\n",
    "- **LLM**: HuggingFace Inference API (openai/gpt-oss-20b:nebius)\n",
    "- **Document Processing**: PyPDF2 for PDF extraction\n",
    "- **State Management**: TypedDict for type-safe state flow\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
